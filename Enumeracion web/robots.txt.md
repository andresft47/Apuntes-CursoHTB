# robots.txt
Es un archivo de texto ubicado en la raíz de un sitio web (`/robots.txt`) que indica a los motores de búsqueda qué rutas no deben indexar.
Los crawlers (como Googlebot) lo leen antes de indexar contenido. Aunque es solo una recomendación, puede revelar rutas sensibles si fue mal configurado.


